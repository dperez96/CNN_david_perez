{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "test_cnns.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hjLVC0C-142",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras \n",
        "from tqdm import tqdm\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "import IPython.display as display\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import os\n",
        "import pathlib\n",
        "import datetime\n",
        "import time\n",
        "from google.colab import files\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "from google.colab import drive\n",
        "\n",
        "#drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8swRCC6-6dY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "train_data_dir= '/content/drive/My Drive/images_dataset'\n",
        "CATEGORIES  = ['MEL_cropped','BKL_cropped', 'BCC_cropped']\n",
        "IMG_SIZE = 80\n",
        "\n",
        "training_data = []\n",
        "\n",
        "def create_training_data():\n",
        "  # this function takes the images and makes them into an array of np arrays and an array of labels\n",
        "  for category in CATEGORIES:\n",
        "    path = os.path.join(train_data_dir,category)\n",
        "    class_num = CATEGORIES.index(category)\n",
        "    for img in tqdm(os.listdir(path)):\n",
        "      img_array = cv2.imread(os.path.join(path,img))  # convert to array\n",
        "      new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
        "      training_data.append([new_array, class_num])\n",
        "      \n",
        "\n",
        "create_training_data()\n",
        "\n",
        "import random\n",
        "\n",
        "random.shuffle(training_data)\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "for features,label in training_data:\n",
        "    X.append(features)\n",
        "    y.append(label)\n",
        "\n",
        "X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1l-2Ms21CrHF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = np.array(X/255.0)#normalisation\n",
        "y=np.array(y)\n",
        "\n",
        "batch_size = 20\n",
        "\n",
        "dense_layers = [3,4,5] \n",
        "conv_layer_sizes = [32]\n",
        "dense_layer_sizes=[32]\n",
        "conv_layers = [3]\n",
        "\n",
        "for dense_layer in dense_layers:\n",
        "    for conv_layer_size in conv_layer_sizes:\n",
        "      for dense_layer_size in dense_layer_sizes:\n",
        "        for conv_layer in conv_layers:\n",
        "            NAME = \"{}-conv-{}-conv_nodes-{}-nodes-{}-dense-{}\".format(conv_layer, conv_layer_size, dense_layer_size, dense_layer, int(time.time()))\n",
        "            print(NAME)\n",
        "            #tf.reset_default_graph()\n",
        "            model = Sequential()\n",
        "\n",
        "            model.add(Conv2D(conv_layer_size, (3, 3), input_shape=X.shape[1:]))\n",
        "            model.add(Activation('relu'))\n",
        "            model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "            for l in range(conv_layer-1):\n",
        "                  model.add(Conv2D(conv_layer_size, (3, 3)))\n",
        "                  model.add(Activation('relu'))\n",
        "                  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "            \n",
        "            model.add(Flatten())\n",
        "            for _ in range(dense_layer):\n",
        "                model.add(Dense(dense_layer_size))\n",
        "                model.add(Activation('relu'))\n",
        "\n",
        "\n",
        "            model.add(Dense(3))\n",
        "            model.add(Activation('softmax'))\n",
        "\n",
        "            model.compile(loss=keras.losses.SparseCategoricalCrossentropy(),\n",
        "                          optimizer='adam',\n",
        "                          metrics=['accuracy'])\n",
        "            \n",
        "            #model.summary()\n",
        "            logdir = \"logs/{}\".format(NAME)\n",
        "            tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
        "\n",
        "            model.fit(X, y,\n",
        "                        batch_size=batch_size,\n",
        "                        epochs=10,\n",
        "                        validation_split=0.1,\n",
        "                        callbacks=[tensorboard_callback])\n",
        "        \n",
        "\n",
        "            \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVfhT41iK9Ah",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!zip -r /content/file.zip /content/logs\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hq2cd0VaBccs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files.download(\"/content/file.zip\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xw5XBul4HMS5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext tensorboard"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFIOg10LHQQh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorboard --logdir logs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dj3JTqadLqm5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcop85s9XoPt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#this part of the script is used to preprocess the validation dataset\n",
        "\n",
        "test_data_dir= '/content/drive/My Drive/images_dataset/Test_Dataset'\n",
        "CATEGORIES  = ['MEL','BKL', 'BCC']\n",
        "IMG_SIZE = 80\n",
        "\n",
        "testing_data = []\n",
        "\n",
        "def create_testing_data():\n",
        "  for category in CATEGORIES:\n",
        "    path = os.path.join(test_data_dir,category)\n",
        "    class_num = CATEGORIES.index(category)\n",
        "    for img in tqdm(os.listdir(path)):\n",
        "      img_array = cv2.imread(os.path.join(path,img))  # convert to array\n",
        "      new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
        "      testing_data.append([new_array, class_num])\n",
        "      \n",
        "\n",
        "create_testing_data()\n",
        "\n",
        "import random\n",
        "\n",
        "random.shuffle(testing_data)\n",
        "\n",
        "X_test = []\n",
        "y_test = []\n",
        "\n",
        "for features,label in testing_data:\n",
        "    X_test.append(features)\n",
        "    y_test.append(label)\n",
        "\n",
        "X_test = np.array(X_test).reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n",
        "y_test=np.array(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdRYk84uViFW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.evaluate(X_test,y_test,batch_size=20)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}